{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"VJAg_5Dr7I2y","colab_type":"code","outputId":"65e677bf-7401-47a8-a21e-303ecb81dcab","executionInfo":{"status":"ok","timestamp":1575839772823,"user_tz":300,"elapsed":31922,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J6OQQyow76P4","colab_type":"code","outputId":"a14eb744-0187-4684-8554-0894277c0efb","executionInfo":{"status":"ok","timestamp":1575839781945,"user_tz":300,"elapsed":3056,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":114}},"source":["import numpy as np\n","import pandas as pd\n","import string\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.stem.porter import PorterStemmer\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords \n","import tensorflow as tf\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, LSTM, CuDNNLSTM, Input, Embedding, TimeDistributed, Flatten, Dropout\n","from keras.callbacks import ModelCheckpoint\n","\n","#!pip install mxnet-cu80\n","#import mxnet as mx"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vS0jK7ye7NzQ","colab_type":"code","colab":{}},"source":["df = pd.read_csv('/content/gdrive/My Drive/Consumer_Complaints.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_IctPMfF8EBU","colab_type":"code","outputId":"e96114e3-038d-44bb-9984-00c03457095b","executionInfo":{"status":"ok","timestamp":1575840046115,"user_tz":300,"elapsed":1189,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date received</th>\n","      <th>Product</th>\n","      <th>Sub-product</th>\n","      <th>Issue</th>\n","      <th>Sub-issue</th>\n","      <th>Consumer complaint narrative</th>\n","      <th>Company public response</th>\n","      <th>Company</th>\n","      <th>State</th>\n","      <th>ZIP code</th>\n","      <th>Tags</th>\n","      <th>Consumer consent provided?</th>\n","      <th>Submitted via</th>\n","      <th>Date sent to company</th>\n","      <th>Company response to consumer</th>\n","      <th>Timely response?</th>\n","      <th>Consumer disputed?</th>\n","      <th>Complaint ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>08/09/2015</td>\n","      <td>Credit reporting</td>\n","      <td>NaN</td>\n","      <td>Incorrect information on credit report</td>\n","      <td>Information is not mine</td>\n","      <td>NaN</td>\n","      <td>Company chooses not to provide a public response</td>\n","      <td>Experian Information Solutions Inc.</td>\n","      <td>NJ</td>\n","      <td>08872</td>\n","      <td>NaN</td>\n","      <td>Consent not provided</td>\n","      <td>Web</td>\n","      <td>08/09/2015</td>\n","      <td>Closed with non-monetary relief</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>1509954</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01/29/2019</td>\n","      <td>Credit reporting, credit repair services, or o...</td>\n","      <td>Credit reporting</td>\n","      <td>Problem with a credit reporting company's inve...</td>\n","      <td>Was not notified of investigation status or re...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>EQUIFAX, INC.</td>\n","      <td>NY</td>\n","      <td>10801</td>\n","      <td>NaN</td>\n","      <td>Consent not provided</td>\n","      <td>Web</td>\n","      <td>01/30/2019</td>\n","      <td>Closed with non-monetary relief</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>3136759</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10/13/2019</td>\n","      <td>Debt collection</td>\n","      <td>I do not know</td>\n","      <td>Attempts to collect debt not owed</td>\n","      <td>Debt was result of identity theft</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>SANTANDER CONSUMER USA HOLDINGS INC.</td>\n","      <td>GA</td>\n","      <td>300XX</td>\n","      <td>Servicemember</td>\n","      <td>NaN</td>\n","      <td>Web</td>\n","      <td>10/13/2019</td>\n","      <td>Closed with explanation</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>3404213</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>08/19/2015</td>\n","      <td>Mortgage</td>\n","      <td>Conventional adjustable mortgage (ARM)</td>\n","      <td>Loan servicing, payments, escrow account</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Company chooses not to provide a public response</td>\n","      <td>WELLS FARGO &amp; COMPANY</td>\n","      <td>CA</td>\n","      <td>94526</td>\n","      <td>NaN</td>\n","      <td>Consent not provided</td>\n","      <td>Web</td>\n","      <td>08/19/2015</td>\n","      <td>Closed with explanation</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>1527601</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>03/04/2016</td>\n","      <td>Credit card</td>\n","      <td>NaN</td>\n","      <td>Billing disputes</td>\n","      <td>NaN</td>\n","      <td>I am dissatisfied with the current outcome of ...</td>\n","      <td>NaN</td>\n","      <td>DISCOVER BANK</td>\n","      <td>NV</td>\n","      <td>891XX</td>\n","      <td>NaN</td>\n","      <td>Consent provided</td>\n","      <td>Web</td>\n","      <td>03/04/2016</td>\n","      <td>Closed with explanation</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>1816726</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Date received  ... Complaint ID\n","0    08/09/2015  ...      1509954\n","1    01/29/2019  ...      3136759\n","2    10/13/2019  ...      3404213\n","3    08/19/2015  ...      1527601\n","4    03/04/2016  ...      1816726\n","\n","[5 rows x 18 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"EdO0SsEYK5vU","colab_type":"code","colab":{}},"source":["df = df.loc[df['Consumer complaint narrative'].isnull()==False,:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X3q1shfB_h7o","colab_type":"code","colab":{}},"source":["df['issue_combined'] = df['Sub-issue']\n","df.loc[df['issue_combined'].isnull()==True,'issue_combined'] = df['Issue']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1GUtPL2AM0G","colab_type":"code","colab":{}},"source":["df['complaints'] = df['Consumer complaint narrative']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSD5YOTBa8Z8","colab_type":"code","colab":{}},"source":["sample = df.sample(n=10000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"agd6VK1Pa5W8","colab_type":"code","colab":{}},"source":["complaints = sample['complaints']\n","issues = sample['issue_combined']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BIKyq4moAp0l","colab_type":"code","colab":{}},"source":["complaints = complaints.apply(lambda x: str(x).lower())\n","issues = issues.apply(lambda x: str(x).lower())\n","issues = issues.apply(lambda x : 'SOS_ '+ x + ' _EOS')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fP-6qh3ABVDS","colab_type":"code","colab":{}},"source":["def cleanup(text):\n","  cleaned = text\n","  cleaned = [re.sub(\"'\", ' ', x) for x in cleaned]\n","  cleaned = [re.sub('\"', ' ', x) for x in cleaned]\n","  cleaned = [re.sub(\",\", ' ', x) for x in cleaned]\n","  cleaned = [re.sub(\"xx\", ' ', x) for x in cleaned]\n","  cleaned = [re.sub(\" x \", ' ', x) for x in cleaned]\n","  exclude = set(string.punctuation)\n","  cleaned = [''.join(char for char in x if char not in exclude) for x in cleaned]\n","  numbers = set(string.digits)\n","  cleaned = [''.join(char for char in x if char not in numbers) for x in cleaned]\n","  cleaned = [re.sub(\"  \", ' ', x) for x in cleaned]\n","  return cleaned\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QLeG59uvDzhr","colab_type":"code","colab":{}},"source":["complaints = cleanup(complaints)\n","issues = cleanup(issues)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"thBG1WB0Kqaq","colab_type":"code","colab":{}},"source":["stemmer = PorterStemmer()\n","#tokenizer = word_tokenize()\n","stop_words = set(stopwords.words('english')) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWfYLkq0D-a1","colab_type":"code","colab":{}},"source":["words_complaints = set()\n","for complaint in complaints:\n","  for word in complaint.split():\n","    #word = stemmer.stem(word)\n","    if word not in words_complaints: #and word not in stop_words:\n","      words_complaints.add(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCirN5_BKqOq","colab_type":"code","colab":{}},"source":["words_issues = set()\n","for issue in issues:\n","  for word in issue.split():\n","    #word = stemmer.stem(word)\n","    if word not in words_issues: #and word not in stop_words\n","      words_issues.add(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sfychobBMsXQ","colab_type":"code","colab":{}},"source":["num_complaint_words = len(words_complaints)\n","num_issue_words = len(words_issues)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_vrudIAsNHjm","colab_type":"code","outputId":"99f6ea6d-e4dd-426f-8be8-4fd499cb132f","executionInfo":{"status":"ok","timestamp":1575840189308,"user_tz":300,"elapsed":1427,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(num_complaint_words)\n","print(num_issue_words)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["20887\n","467\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"43qWA3fqNJTW","colab_type":"code","colab":{}},"source":["max_complaint_words = max([len(complaint.split()) for complaint in complaints])\n","max_issue_words = max([len(issue.split()) for issue in issues])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTAJwMyoNK9L","colab_type":"code","outputId":"be848ac9-9d61-4c21-de57-2d06689cf5f3","executionInfo":{"status":"ok","timestamp":1575840201573,"user_tz":300,"elapsed":1167,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(max_complaint_words)\n","print(max_issue_words)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["5085\n","19\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-grB9CydN0NL","colab_type":"code","outputId":"53058bbf-f614-42c8-ebe2-0d81d9fb1164","executionInfo":{"status":"ok","timestamp":1575840208223,"user_tz":300,"elapsed":1328,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["num_complaints = len(complaints)\n","num_issues = len(issues)\n","\n","print(num_complaints)\n","print(num_issues)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["10000\n","10000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ClB8W-arOA4q","colab_type":"code","colab":{}},"source":["encoder_word_to_int = dict()\n","encoder_int_to_word = dict()\n","\n","decoder_word_to_int = dict()\n","decoder_int_to_word = dict()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3iBPEhf1OfpK","colab_type":"code","colab":{}},"source":["input_words = list(words_complaints)\n","target_words = list(words_issues)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tINqWenOoTI","colab_type":"code","colab":{}},"source":["for row, word in enumerate(input_words):\n","  encoder_word_to_int[word] = row\n","  encoder_int_to_word[row] = word"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YGesCCxPv6z","colab_type":"code","colab":{}},"source":["for row, word in enumerate(target_words):\n","  decoder_word_to_int[word] = row\n","  decoder_int_to_word[row] = word"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sAL3M86_P3ot","colab_type":"code","colab":{}},"source":["# initiate numpy arrays to hold the data that our seq2seq model will use:\n","encoder_input_data = np.zeros(\n","    (num_complaints, max_complaint_words),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (num_issues, max_issue_words),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (num_issues, max_issue_words, num_issue_words),\n","    dtype='float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YM_moJkaSEkg","colab_type":"code","colab":{}},"source":["# Process samples, to get input, output, target data:\n","for i, (input_text, target_text) in enumerate(zip(complaints, issues)):\n","    for t, word in enumerate(input_text.split()):\n","        encoder_input_data[i, t] = encoder_word_to_int[word]\n","    for t, word in enumerate(target_text.split()):\n","        # decoder_target_data is ahead of decoder_input_data by one timestep\n","        decoder_input_data[i, t] = decoder_word_to_int[word]\n","        if t > 0:\n","            # decoder_target_data will be ahead by one timestep\n","            # and will not include the start character.\n","            decoder_target_data[i, t - 1, decoder_word_to_int[word]] = 1."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHl4HFQPbYev","colab_type":"code","colab":{}},"source":["vec_len       = 100   # Length of the vector that we will get from the embedding layer\n","latent_dim    = 200  # Hidden layers dimension \n","dropout_rate  = 0.2   # Rate of the dropout layers\n","batch_size    = 40    # Batch size\n","epochs        = 3    # Number of epochs\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzhk269qdjKx","colab_type":"code","outputId":"81764936-5c2a-4064-af5d-c78401961e2d","executionInfo":{"status":"ok","timestamp":1575840291406,"user_tz":300,"elapsed":1698,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["# Define an input sequence and process it.\n","# Input layer of the encoder :\n","encoder_input = Input(shape=(None,))\n","\n","# Hidden layers of the encoder :\n","encoder_embedding = Embedding(input_dim = num_complaint_words, output_dim = vec_len)(encoder_input)\n","encoder_dropout   = (TimeDistributed(Dropout(rate = dropout_rate)))(encoder_embedding)\n","encoder_LSTM      = LSTM(latent_dim, return_sequences=True)(encoder_dropout)\n","#CuDNNLSTM\n","\n","# Output layer of the encoder :\n","encoder_LSTM2_layer = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_LSTM2_layer(encoder_LSTM)\n","\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G8O5jmO3d2ev","colab_type":"code","colab":{}},"source":["# Set up the decoder, using `encoder_states` as initial state.\n","# Input layer of the decoder :\n","decoder_input = Input(shape=(None,))\n","\n","# Hidden layers of the decoder :\n","decoder_embedding_layer = Embedding(input_dim = num_issue_words, output_dim = vec_len)\n","decoder_embedding = decoder_embedding_layer(decoder_input)\n","\n","decoder_dropout_layer = (TimeDistributed(Dropout(rate = dropout_rate)))\n","decoder_dropout = decoder_dropout_layer(decoder_embedding)\n","\n","decoder_LSTM_layer = LSTM(latent_dim, return_sequences=True)\n","decoder_LSTM = decoder_LSTM_layer(decoder_dropout, initial_state = encoder_states)\n","\n","decoder_LSTM_2_layer = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_LSTM_2,_,_ = decoder_LSTM_2_layer(decoder_LSTM)\n","\n","# Output layer of the decoder :\n","decoder_dense = Dense(num_issue_words, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_LSTM_2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X7hxexz8eKJJ","colab_type":"code","outputId":"e8d3357e-ebbb-4be9-ad7e-1ec96b5e6d3e","executionInfo":{"status":"ok","timestamp":1575840311765,"user_tz":300,"elapsed":1205,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":561}},"source":["\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_input, decoder_input], decoder_outputs)\n","\n","model.summary()\n","\n","# Define a checkpoint callback :\n","checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n","checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, None, 100)    2088700     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None)         0                                            \n","__________________________________________________________________________________________________\n","time_distributed_1 (TimeDistrib (None, None, 100)    0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, None, 100)    46700       input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   (None, None, 200)    240800      time_distributed_1[0][0]         \n","__________________________________________________________________________________________________\n","time_distributed_2 (TimeDistrib (None, None, 100)    0           embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   [(None, 200), (None, 320800      lstm_1[0][0]                     \n","__________________________________________________________________________________________________\n","lstm_3 (LSTM)                   (None, None, 200)    240800      time_distributed_2[0][0]         \n","                                                                 lstm_2[0][1]                     \n","                                                                 lstm_2[0][2]                     \n","__________________________________________________________________________________________________\n","lstm_4 (LSTM)                   [(None, None, 200),  320800      lstm_3[0][0]                     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, None, 467)    93867       lstm_4[0][0]                     \n","==================================================================================================\n","Total params: 3,352,467\n","Trainable params: 3,352,467\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RiqEQp8okCu_","colab_type":"code","colab":{}},"source":["config = tf.ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.3\n","tf.compat.v1.keras.backend.set_session(tf.Session(config=config))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5KFyDdfGeUnd","colab_type":"code","outputId":"9108cf54-65f1-4b53-b10e-8344815c42b5","executionInfo":{"status":"ok","timestamp":1575840862576,"user_tz":300,"elapsed":535740,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":496}},"source":["num_train_samples = 500\n","# Run training\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","model.fit([encoder_input_data[:num_train_samples,:],\n","               decoder_input_data[:num_train_samples,:]],\n","               decoder_target_data[:num_train_samples,:,:],\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.08 ) #,\n","          #callbacks = None) #callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 460 samples, validate on 40 samples\n","Epoch 1/3\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","460/460 [==============================] - 184s 401ms/step - loss: 1.7806 - val_loss: 1.5819\n","Epoch 2/3\n","460/460 [==============================] - 175s 380ms/step - loss: 1.5613 - val_loss: 1.5106\n","Epoch 3/3\n","460/460 [==============================] - 173s 375ms/step - loss: 1.4989 - val_loss: 1.4644\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7efe00d68c18>"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"lfXTZhAVexT9","colab_type":"code","outputId":"e50e4013-d53e-422b-deec-14c9c1eb0b13","executionInfo":{"status":"error","timestamp":1575842046707,"user_tz":300,"elapsed":1459,"user":{"displayName":"Kim Evarista","photoUrl":"","userId":"02432235147190009540"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["encoder_model = Model(encoder_input, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_LSTM(decoder_input #decoder_LSTM\n","    , initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_input] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-5c918b0202e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecoder_states_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdecoder_state_input_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_state_input_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m decoder_outputs, state_h, state_c = decoder_LSTM(decoder_input #decoder_LSTM\n\u001b[0;32m----> 7\u001b[0;31m     , initial_state=decoder_states_inputs)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdecoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"]}]},{"cell_type":"code","metadata":{"id":"DP8hZaQyOD2H","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}